import sys
import os
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from tqdm import tqdm
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix

# ThÃªm Ä‘Æ°á»ng dáº«n project
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data_logic.ham_dataset import HAM10000Dataset
from src.data_logic.bcn_dataset import DermoscopyDataset
from src.models import get_model

# Import GradCAM
try:
    from pytorch_grad_cam import GradCAM
    from pytorch_grad_cam.utils.image import show_cam_on_image
    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget

    HAS_GRADCAM = True
except ImportError:
    HAS_GRADCAM = False
    print("âš ï¸ ChÆ°a cÃ i 'grad-cam'. Cháº¡y 'pip install grad-cam' Ä‘á»ƒ dÃ¹ng tÃ­nh nÄƒng nÃ y.")

# ==========================================
# Cáº¤U HÃŒNH TEST
# ==========================================
CONFIG = {
    # Chá»n Dataset muá»‘n test: 'HAM10000' hoáº·c 'BCN20000'
    # 'DATASET': 'HAM10000',
    #
    # # ÄÆ°á»ng dáº«n file CSV Test (Sá»­a láº¡i cho Ä‘Ãºng Ä‘Æ°á»ng dáº«n cá»§a báº¡n)
    # 'TEST_CSV': '/mnt/d/skin_cancer_project/dataset/metadata/ham10000_test.csv',
    #
    # # ÄÆ°á»ng dáº«n folder áº£nh Ä‘Ã£ xá»­ lÃ½ (Cleaned)
    # 'IMG_ROOT': '/mnt/d/skin_cancer_project/dataset/Ham10000-preprocessed',
    #
    # # ÄÆ°á»ng dáº«n Checkpoint tá»‘t nháº¥t
    # 'CKPT_PATH': '/mnt/d/skin_cancer_project/checkpoint_ResNet50_ham10000/best_full_weighted.pt',

    'DATASET': 'BCN20000',

    # ÄÆ°á»ng dáº«n file CSV Test (Sá»­a láº¡i cho Ä‘Ãºng Ä‘Æ°á»ng dáº«n cá»§a báº¡n)
    'TEST_CSV': '/mnt/d/skin_cancer_project/dataset/metadata/bcn20000_test.csv',

    # ÄÆ°á»ng dáº«n folder áº£nh Ä‘Ã£ xá»­ lÃ½ (Cleaned)
    'IMG_ROOT': '/mnt/d/skin_cancer_project/dataset/Bcn20000-preprocessed',

    # ÄÆ°á»ng dáº«n Checkpoint tá»‘t nháº¥t
    'CKPT_PATH': '/mnt/d/skin_cancer_project/checkpoint_ResNet50_bcn20000/best_full_weighted.pt',

    # Cáº¥u hÃ¬nh Model (Pháº£i khá»›p lÃºc Train)
    'MODEL_NAME': 'resnet50',
    'IMG_SIZE': 384,
    'METADATA_MODE': 'full_weighted',
    'METADATA_FEATURE_BOOST': 5.0,
    'PRETRAINED': False,  # KhÃ´ng cáº§n load pretrain ImageNet vÃ¬ ta load checkpoint cá»§a mÃ¬nh
    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',
    'BATCH_SIZE': 16
}


# Náº¿u test BCN thÃ¬ bá» comment Ä‘oáº¡n nÃ y
# CONFIG['DATASET'] = 'BCN20000'
# CONFIG['TEST_CSV'] = '/mnt/d/skin_cancer_project/dataset/metadata/bcn20000_test.csv'
# CONFIG['IMG_ROOT'] = '/mnt/d/skin_cancer_project/dataset/Bcn20000-cleaned-final'
# CONFIG['CKPT_PATH'] = '/mnt/d/skin_cancer_project/checkpoint_ResNet50_bcn20000/best_full_weighted.pt'


def generate_gradcam_report(model, test_loader, device, save_dir, num_samples=10):
    """
    Váº½ GradCAM cho má»™t sá»‘ máº«u trong táº­p test
    """
    if not HAS_GRADCAM: return

    print(f"\nðŸŽ¨ Äang táº¡o {num_samples} áº£nh Grad-CAM máº«u...")
    os.makedirs(save_dir, exist_ok=True)

    model.eval()

    # --- Sá»¬A Lá»–I Táº I ÄÃ‚Y ---
    # Model Ä‘áº§u vÃ o lÃ  'GradCAMModelWrapper', model tháº­t náº±m trong biáº¿n '.model'
    # Path: wrapper -> ResNetCBAM -> ResNet50Backbone -> torchvision ResNet -> layer4
    try:
        # Náº¿u lÃ  wrapper (GradCAMModelWrapper)
        real_backbone = model.model.backbone.model
    except AttributeError:
        # Náº¿u khÃ´ng pháº£i wrapper (trÆ°á»ng há»£p dÃ¹ng model tráº§n)
        try:
            real_backbone = model.backbone.model
        except AttributeError:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y backbone.model.layer4. Kiá»ƒm tra láº¡i cáº¥u trÃºc model!")
            return

    target_layers = [real_backbone.layer4[-1]]
    # -----------------------

    cam = GradCAM(model=model, target_layers=target_layers)

    # Láº¥y 1 batch tá»« test_loader
    imgs, meta, labels = next(iter(test_loader))
    imgs = imgs.to(device)

    # Chá»n ngáº«u nhiÃªn hoáº·c láº¥y tuáº§n tá»±
    for idx in range(min(num_samples, len(imgs))):
        img_tensor = imgs[idx:idx + 1]  # (1, C, H, W)
        label_true = labels[idx].item()

        # Metadata (Fake batch dimension)
        # m_num = meta[0][idx:idx + 1].to(device).float()
        # m_cat = meta[1][idx:idx + 1].to(device).long()

        # --- CHáº Y GRADCAM ---
        try:
            # Denormalize áº£nh Ä‘á»ƒ hiá»ƒn thá»‹
            rgb_img = img_tensor.cpu().numpy().squeeze().transpose(1, 2, 0)
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            rgb_img = std * rgb_img + mean
            rgb_img = np.clip(rgb_img, 0, 1)

            # TÃ­nh CAM (Target lÃ  class Malignant = 1)
            # targets = [ClassifierOutputTarget(0)] # LÃ nh tÃ­nh
            # targets = [ClassifierOutputTarget(0)]  # Binary Classification: Output lÃ  Logits

            # Vá»›i Binary Classification, targets=None sáº½ tá»± Ä‘á»™ng chá»n class cÃ³ score cao nháº¥t
            grayscale_cam = cam(input_tensor=img_tensor, targets=None)[0]

            visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

            # LÆ°u áº£nh
            fname = f"cam_sample_{idx}_True{int(label_true)}.png"
            cv2.imwrite(os.path.join(save_dir, fname), cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR))

        except Exception as e:
            print(f"âš ï¸ Lá»—i váº½ CAM áº£nh {idx}: {e}")
            continue

    print(f"âœ… ÄÃ£ lÆ°u áº£nh GradCAM vÃ o: {save_dir}")


# Wrapper cho Model Ä‘á»ƒ GradCAM dá»… gá»i (chá»‰ nháº­n 1 input áº£nh)
class GradCAMModelWrapper(nn.Module):
    def __init__(self, model, dummy_meta_num, dummy_meta_cat):
        super().__init__()
        self.model = model
        self.meta_num = dummy_meta_num
        self.meta_cat = dummy_meta_cat

    def forward(self, x):
        return self.model(x, self.meta_num, self.meta_cat)


def main():
    device = torch.device(CONFIG['DEVICE'])
    print(f"ðŸš€ Báº®T Äáº¦U TEST TRÃŠN Táº¬P: {CONFIG['DATASET']}")

    # 1. Load Data
    df = pd.read_csv(CONFIG['TEST_CSV'])
    df.columns = df.columns.str.strip()

    # Xá»­ lÃ½ label & path
    if CONFIG['DATASET'] == 'HAM10000':
        if 'dx' in df.columns:
            df['label'] = df['dx'].apply(lambda x: 1 if x in ['mel', 'bcc', 'akiec'] else 0)
        df['image_path'] = df['image_id'].astype(str) + '.jpg'
        DatasetClass = HAM10000Dataset
    else:
        # BCN logic
        if 'diagnosis' in df.columns:
            df['label'] = df['diagnosis'].apply(
                lambda x: 1 if str(x).lower() in ['melanoma', 'basal cell carcinoma', 'squamous cell carcinoma'] else 0)
        elif 'diagnosis_1' in df.columns:
            df['label'] = df['diagnosis_1'].apply(lambda x: 1 if 'malig' in str(x).lower() else 0)
        if 'isic_id' in df.columns:
            df['image_path'] = df['isic_id'].astype(str) + '.jpg'
        DatasetClass = DermoscopyDataset

    # Quan trá»ng: Dataset test luÃ´n load clean_
    # VÃ¬ logic load áº£nh Ä‘Ã£ náº±m trong _load_image cá»§a Dataset (tá»± thÃªm clean_)

    print("â³ Äang load model...")
    # Táº¡o dataset táº¡m Ä‘á»ƒ láº¥y thÃ´ng tin cá»™t
    temp_ds = DatasetClass(df, CONFIG['IMG_ROOT'], CONFIG['IMG_SIZE'], CONFIG['METADATA_MODE'], train=False)

    # Khá»Ÿi táº¡o model
    model = get_model(CONFIG, temp_ds.cat_cardinalities, len(temp_ds.numeric_cols)).to(device)

    # --- ÄOáº N CODE LOAD CHECKPOINT THÃ”NG MINH ---
    print(f"â³ Äang load checkpoint: {CONFIG['CKPT_PATH']}")
    checkpoint = torch.load(CONFIG['CKPT_PATH'], map_location=device)
    state_dict = checkpoint['state_dict']

    # 1. Láº¥y state_dict hiá»‡n táº¡i cá»§a model
    model_state_dict = model.state_dict()

    # 2. Lá»c bá» cÃ¡c key bá»‹ lá»‡ch kÃ­ch thÆ°á»›c (Size Mismatch)
    # Ta sáº½ chá»‰ giá»¯ láº¡i nhá»¯ng key nÃ o cÃ³ cÃ¹ng kÃ­ch thÆ°á»›c vá»›i model hiá»‡n táº¡i
    filtered_state_dict = {}
    mismatched_keys = []

    for k, v in state_dict.items():
        if k in model_state_dict:
            if v.shape == model_state_dict[k].shape:
                filtered_state_dict[k] = v
            else:
                mismatched_keys.append(k)
        else:
            pass

    if mismatched_keys:
        print(f"âš ï¸ Cáº£nh bÃ¡o: ÄÃ£ bá» qua {len(mismatched_keys)} layer bá»‹ lá»‡ch kÃ­ch thÆ°á»›c (do RFE/Metadata khÃ¡c biá»‡t).")
        # print(f"   VÃ­ dá»¥: {mismatched_keys[:3]}...")

    # 3. Load state_dict Ä‘Ã£ lá»c (dÃ¹ng strict=False Ä‘á»ƒ cháº¥p nháº­n thiáº¿u key)
    model.load_state_dict(filtered_state_dict, strict=False)
    print("âœ… Load model thÃ nh cÃ´ng (Backbone & Attention Ä‘Ã£ Ä‘Æ°á»£c náº¡p chuáº©n).")

    model.eval()

    # 2. Táº¡o DataLoader
    test_loader = DataLoader(temp_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=0)

    # 3. Cháº¡y Inference
    print("running inference...")
    all_probs = []
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for imgs, meta, labels in tqdm(test_loader):
            imgs = imgs.to(device)
            labels = labels.to(device)
            m_num, m_cat = meta
            m_num, m_cat = m_num.to(device).float(), m_cat.to(device).long()

            logits = model(imgs, m_num, m_cat)
            probs = torch.sigmoid(logits).cpu().numpy().flatten()

            all_probs.extend(probs)
            # Thá»­ ngÆ°á»¡ng tháº¥p hÆ¡n vÃ¬ Recall Ä‘ang tháº¥p (0.43)
            # all_preds.extend((probs >= 0.5).astype(int))
            all_preds.extend((probs >= 0.3).astype(int))
            all_targets.extend(labels.cpu().numpy())

    # 4. TÃ­nh Metrics
    auc = roc_auc_score(all_targets, all_probs)
    acc = accuracy_score(all_targets, all_preds)
    cm = confusion_matrix(all_targets, all_preds)
    tn, fp, fn, tp = cm.ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    print("\n" + "=" * 40)
    print(f"ðŸ“Š Káº¾T QUáº¢ TEST TRÃŠN {CONFIG['DATASET']}")
    print("=" * 40)
    print(f"âœ… AUC          : {auc:.4f}")
    print(f"âœ… Accuracy     : {acc:.4f}")
    print(f"âœ… Sensitivity  : {sensitivity:.4f} (Recall)")
    print(f"âœ… Specificity  : {specificity:.4f}")
    if (tp + fp) > 0:
        print(f"âœ… Precision    : {tp / (tp + fp):.4f}")
    else:
        print(f"âœ… Precision    : 0.0000")

    print("\nConfusion Matrix:")
    print(cm)

    # 5. Váº½ GradCAM (DÃ¹ng Wrapper Ä‘á»ƒ xá»­ lÃ½ vá»¥ 3 tham sá»‘ Ä‘áº§u vÃ o)
    # Láº¥y 1 máº«u metadata lÃ m dummy
    sample_img, sample_meta, _ = temp_ds[0]
    dummy_num = sample_meta[0].unsqueeze(0).to(device).float()
    dummy_cat = sample_meta[1].unsqueeze(0).to(device).long()

    wrapped_model = GradCAMModelWrapper(model, dummy_num, dummy_cat)

    # Folder lÆ°u káº¿t quáº£
    res_dir = os.path.join(os.path.dirname(CONFIG['CKPT_PATH']), 'test_results')
    generate_gradcam_report(wrapped_model, test_loader, device, res_dir)

    print(f"\nðŸŽ‰ HoÃ n táº¥t! Káº¿t quáº£ lÆ°u táº¡i {res_dir}")


if __name__ == "__main__":
    main()