import sys
import os
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader, WeightedRandomSampler
from sklearn.feature_selection import RFECV
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt

# Th√™m ƒë∆∞·ªùng d·∫´n g·ªëc c·ªßa project
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data_logic.ham_dataset import HAM10000Dataset
from src.models import get_model
from src.utils.losses import FocalLoss
from src.utils.common import seed_everything, get_warmup_cosine_scheduler, set_finetune_mode
from src.utils.trainer import train_loop

# ------------------- CONFIG -------------------
CONFIG = {
    'TRAIN_CSV': '/mnt/d/skin_cancer_project/dataset/metadata/ham10000_train.csv',
    'VAL_CSV': '/mnt/d/skin_cancer_project/dataset/metadata/ham10000_val.csv',
    'TEST_CSV': '/mnt/d/skin_cancer_project/dataset/metadata/ham10000_test.csv',
    'IMG_ROOT': '/mnt/d/skin_cancer_project/dataset/Ham10000-preprocessed',
    'MODEL_OUT':  '/mnt/d/skin_cancer_project/checkpoint_ResNet50_ham10000',
    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu', 
    'SEED': 42, 
    'IMG_SIZE': 384,
    'BATCH_SIZE': 16,
    'MODEL_NAME': 'resnet50',

    # --- C·∫¨P NH·∫¨T CHI·∫æN L∆Ø·ª¢C H·ªåC (STRATEGY) ---

    'EPOCHS': 20,           # TƒÉng l√™n 20 ƒë·ªÉ h·ªôi t·ª• s√¢u h∆°n
    'BASE_LR': 1e-5,        # Gi·∫£m m·∫°nh (t·ª´ 5e-4 xu·ªëng 8e-5) ƒë·ªÉ Loss m∆∞·ª£t h∆°n
    'WARMUP_EPOCHS': 3,     # TƒÉng Warmup l√™n 3 epoch ƒë·∫ßu
    'WEIGHT_DECAY': 1e-2,   # TƒÉng Weight Decay ƒë·ªÉ ch·ªëng Overfit m·∫°nh h∆°n
    # ------------------------------------------

    'METADATA_MODE': 'full_weighted',
    'METADATA_FEATURE_BOOST': 5.0,
    'PRETRAINED': True, 
    'FINE_TUNE_MODE': 'full_unfreeze',
    'UNFREEZE_SUBSTRINGS': [],
    'USE_SAMPLER': True,
    'ACCUM_STEPS': 1,
    'SHAP_THRESHOLD': 0.005, 
    'NSAMPLES_SHAP': 50       
}

def auto_feature_selection_ham(train_df, config, device):
    """Giai ƒëo·∫°n thƒÉm d√≤: X√°c ƒë·ªãnh c√°c bi·∫øn metadata quan tr·ªçng cho HAM10000"""
    print("\nüîç --- GIAI ƒêO·∫†N: T·ª∞ ƒê·ªòNG L·ªåC BI·∫æN METADATA (SHAP) - HAM10000 ---")
    
    temp_ds = HAM10000Dataset(train_df, config['IMG_ROOT'], config['IMG_SIZE'], config['METADATA_MODE'], train=False)
    temp_model = get_model(config, temp_ds.cat_cardinalities, len(temp_ds.numeric_cols)).to(device)
    temp_model.eval()

    all_meta_features = temp_ds.numeric_cols + temp_ds.categorical_cols
    # Placeholder: Trong th·ª±c t·∫ø s·∫Ω ch·∫°y shap.KernelExplainer
    importance_map = {feat: np.random.uniform(0.001, 0.02) for feat in all_meta_features}

    selected_features = [f for f, imp in importance_map.items() if imp > config['SHAP_THRESHOLD']]
    
    print(f" Bi·∫øn metadata gi·ªØ l·∫°i: {selected_features}")
    return selected_features

def main(config):
    seed_everything(config['SEED'])
    device = torch.device(config['DEVICE'])
    os.makedirs(config['MODEL_OUT'], exist_ok=True)
    
    # Log ki·ªÉm tra GPU
    print("="*50)
    print(f" Thi·∫øt b·ªã ƒëang s·ª≠ d·ª•ng: {device}")
    if device.type == 'cuda':
        print(f"üî• GPU Name: {torch.cuda.get_device_name(0)}")
    print("="*50)

    # 1. T·∫£i v√† chu·∫©n b·ªã d·ªØ li·ªáu
    print(" ƒêang t·∫£i d·ªØ li·ªáu HAM10000...")
    train_df = pd.read_csv(config['TRAIN_CSV'])
    val_df = pd.read_csv(config['VAL_CSV'])
    test_df = pd.read_csv(config['TEST_CSV'])
    
    for df in [train_df, val_df, test_df]:
        df.columns = df.columns.str.strip()
        df['image_path'] = df['image_id'].astype(str) + '.jpg'
        if 'dx' in df.columns: 
            df['label'] = df['dx'].apply(lambda x: 1 if x in ['mel', 'bcc', 'akiec'] else 0)
    
    # 2. SHAP Selection
    important_features = advanced_feature_selection_rfe(train_df, config, device)

    # 3. Kh·ªüi t·∫°o Datasets (V·ªõi b·ªô Strong Augmentation ƒë√£ c·∫≠p nh·∫≠t trong ham_dataset.py)
    train_ds = HAM10000Dataset(train_df, config['IMG_ROOT'], config['IMG_SIZE'], 
                               config['METADATA_MODE'], train=True, selected_features=important_features)
    val_ds = HAM10000Dataset(val_df, config['IMG_ROOT'], config['IMG_SIZE'], 
                             config['METADATA_MODE'], train=False, selected_features=important_features)
    test_ds = HAM10000Dataset(test_df, config['IMG_ROOT'], config['IMG_SIZE'], 
                              config['METADATA_MODE'], train=False, selected_features=important_features)

    # 4. Sampler & Loaders
    train_sampler = None
    if config['USE_SAMPLER']:
        targets = train_df['label'].values
        class_counts = np.bincount(targets)
        weights = 1. / class_counts
        samples_weights = torch.from_numpy(weights[targets]).double()
        train_sampler = WeightedRandomSampler(samples_weights, len(samples_weights))

    train_loader = DataLoader(train_ds, batch_size=config['BATCH_SIZE'], sampler=train_sampler, num_workers=4)
    val_loader = DataLoader(val_ds, batch_size=config['BATCH_SIZE'], shuffle=False, num_workers=4)
    test_loader = DataLoader(test_ds, batch_size=config['BATCH_SIZE'], shuffle=False, num_workers=4)

    # 5. Kh·ªüi t·∫°o Model
    model = get_model(config, train_ds.cat_cardinalities, len(train_ds.numeric_cols)).to(device)
    set_finetune_mode(model, config['FINE_TUNE_MODE'], config['UNFREEZE_SUBSTRINGS'])

    # Optimizer s·ª≠ d·ª•ng BASE_LR v√† WEIGHT_DECAY t·ª´ CONFIG
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=config['BASE_LR'], 
        weight_decay=config['WEIGHT_DECAY']
    )
    
    criterion = FocalLoss(alpha=0.75, gamma=2.0)
    scheduler = get_warmup_cosine_scheduler(optimizer, config['WARMUP_EPOCHS'], config['EPOCHS'])

    # 6. Hu·∫•n luy·ªán
    print("\nüöÄ --- B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN CH√çNH TH·ª®C (HAM10000) ---")
    train_loop(
        model, 
        train_loader, 
        val_loader, 
        test_loader, 
        config, 
        criterion, 
        optimizer, 
        scheduler, 
        device, 
        log_suffix="ham10k_final_enhanced"
    )

def advanced_feature_selection_rfe(train_df, config, device):
    print("\nüîç --- GIAI ƒêO·∫†N: CH·ªåN L·ªåC ƒê·∫∂C TR∆ØNG N√ÇNG CAO (RFECV) ---")

    # 1. Chu·∫©n b·ªã d·ªØ li·ªáu metadata
    # L∆∞u √Ω: train=False ƒë·ªÉ dataset kh√¥ng tr·ªôn ·∫£nh clean/roi lung tung l√∫c n√†y
    temp_ds = HAM10000Dataset(train_df, config['IMG_ROOT'], config['IMG_SIZE'], config['METADATA_MODE'], train=False)
    all_cols = temp_ds.numeric_cols + temp_ds.categorical_cols

    X = train_df[all_cols].copy()
    y = train_df['label'].values

    # X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu (Imputation)
    if temp_ds.numeric_cols:
        num_imputer = SimpleImputer(strategy='mean')
        X[temp_ds.numeric_cols] = num_imputer.fit_transform(X[temp_ds.numeric_cols])

    for col in temp_ds.categorical_cols:
        X[col] = X[col].fillna('unknown').astype(str)
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])

    # 2. Ch·∫°y RFECV (Recursive Feature Elimination with Cross-Validation)
    print("ü§ñ ƒêang ch·∫°y RFE... (Qu√° tr√¨nh n√†y t√¨m t·∫≠p h·ª£p bi·∫øn t·ªëi ∆∞u nh·∫•t)")
    rf = RandomForestClassifier(n_estimators=100, random_state=config['SEED'], n_jobs=-1)
    cv = StratifiedKFold(n_splits=5) # 5-Fold ƒë·ªÉ ƒë·∫£m b·∫£o kh√°ch quan

    # step=1: Lo·∫°i t·ª´ng bi·∫øn m·ªôt. min_features_to_select=3: Gi·ªØ √≠t nh·∫•t 3 bi·∫øn
    selector = RFECV(estimator=rf, step=1, cv=cv, scoring='accuracy', min_features_to_select=3, n_jobs=-1)
    selector = selector.fit(X, y)

    # 3. L·∫•y k·∫øt qu·∫£
    selected_mask = selector.support_
    selected_features = np.array(all_cols)[selected_mask].tolist()

    print(f"üìä S·ªë l∆∞·ª£ng bi·∫øn t·ªëi ∆∞u: {selector.n_features_}/{len(all_cols)}")
    print(f"‚úÖ QUY·∫æT ƒê·ªäNH GI·ªÆ L·∫†I: {selected_features}")

    # V·∫Ω bi·ªÉu ƒë·ªì hi·ªáu nƒÉng (Quan tr·ªçng cho b√†i b√°o)
    plt.figure(figsize=(10, 6))
    plt.xlabel("S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn")
    plt.ylabel("ƒê·ªô ch√≠nh x√°c (Cross Validation Score)")
    plt.plot(range(1, len(selector.cv_results_['mean_test_score']) + 1), selector.cv_results_['mean_test_score'])
    plt.title("Hi·ªáu nƒÉng m√¥ h√¨nh theo s·ªë l∆∞·ª£ng Metadata")
    plt.grid(True)
    plt.savefig(os.path.join(config['MODEL_OUT'], "rfe_performance.png"))
    print("üìà ƒê√£ l∆∞u bi·ªÉu ƒë·ªì RFE v√†o folder checkpoint.")

    return selected_features

if __name__ == '__main__':
    main(CONFIG)