import sys
import os
import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt
from torchvision import transforms
from PIL import Image
from lime import lime_image
from skimage.segmentation import mark_boundaries

# Setup path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from src.models import get_model

# C·∫§U H√åNH LOAD MODEL BCN
CONFIG = {
    'MODEL_NAME': 'resnet50',
    'IMG_SIZE': 384,
    'METADATA_MODE': 'full_weighted',
    'METADATA_FEATURE_BOOST': 5.0,  # L∆∞u √Ω: Train BCN b·∫°n d√πng 5.0
    # 'META_CLASS_WEIGHT_BOOST': 2.0, # C√°i n√†y d√πng t√≠nh Loss l√∫c train, inference ko c·∫ßn
    'PRETRAINED': False,
    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'
}

# ƒê∆Ø·ªúNG D·∫™N C·ª¶A BCN
CKPT_PATH = '/mnt/d/skin_cancer_project/checkpoint_ResNet50_bcn20000/best_full_weighted.pt'

# Ch·ªçn m·ªôt ·∫£nh Test c·ªßa BCN ƒë·ªÉ gi·∫£i th√≠ch
# B·∫°n h√£y thay t√™n file n√†y b·∫±ng m·ªôt file th·ª±c t·∫ø trong folder BCN cleaned c·ªßa b·∫°n
IMG_PATH = '/mnt/d/skin_cancer_project/dataset/Bcn20000-preprocessed/clean_ISIC_0000000.jpg'


def run_lime_bcn():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 1. Load Model
    # Fake metadata cho BCN (BCN c√≥ anatomical_site, age, sex...)
    dummy_cats = {'age': 60, 'anatom_site_general': 2, 'sex': 1}  # V√≠ d·ª• dummy
    dummy_num = 0  # BCN th∆∞·ªùng √≠t numeric features h∆°n HAM, t√πy dataset c·ªßa b·∫°n

    # L∆∞u √Ω: C·∫ßn truy·ªÅn ƒë√∫ng s·ªë l∆∞·ª£ng features kh·ªõp v·ªõi l√∫c train
    # N·∫øu RFE l·ªçc b·ªõt r·ªìi th√¨ ·ªü ƒë√¢y ph·∫£i kh·ªõp.
    # M·∫πo: ƒê·ªÉ ƒë∆°n gi·∫£n l√∫c ch·∫°y LIME, b·∫°n c√≥ th·ªÉ load l·∫°i config ƒë√£ l∆∞u l√∫c train (n·∫øu c√≥)
    # Ho·∫∑c c·ª© ƒë·ªÉ dummy d∆∞ ra, model.load_state_dict s·∫Ω b√°o l·ªói n·∫øu l·ªách dimension.

    model = get_model(CONFIG, dummy_cats, dummy_num).to(device)

    print(f"‚è≥ ƒêang load checkpoint: {CKPT_PATH}")
    checkpoint = torch.load(CKPT_PATH, map_location=device)
    model.load_state_dict(checkpoint['state_dict'],
                          strict=False)  # strict=False ƒë·ªÉ b·ªè qua l·ªói l·ªách head metadata n·∫øu c√≥
    model.eval()

    # 2. H√†m d·ª± ƒëo√°n (Gi·ªëng b√™n HAM)
    def batch_predict(images):
        batch_tensors = []
        for img in images:
            img_pil = Image.fromarray(img.astype('uint8'))
            t = transforms.Compose([
                transforms.Resize((CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'])),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            batch_tensors.append(t(img_pil))

        batch = torch.stack(batch_tensors).to(device)
        B = batch.size(0)

        # Fake metadata
        meta_num = torch.zeros((B, dummy_num)).to(device)
        meta_cat = torch.zeros((B, len(dummy_cats)), dtype=torch.long).to(device)

        with torch.no_grad():
            logits = model(batch, meta_num, meta_cat)
            probs = torch.sigmoid(logits)

        probs = probs.cpu().numpy()
        return np.hstack([1 - probs, probs])

    # 3. Ch·∫°y LIME
    print("üçã ƒêang ch·∫°y LIME cho BCN20000...")
    explainer = lime_image.LimeImageExplainer()

    if not os.path.exists(IMG_PATH):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {IMG_PATH}")
        return

    original_img = np.array(Image.open(IMG_PATH).convert('RGB').resize((CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'])))

    explanation = explainer.explain_instance(
        original_img,
        batch_predict,
        top_labels=1,
        hide_color=0,
        num_samples=1000
    )

    # 4. L∆∞u ·∫£nh
    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5,
                                                hide_rest=False)
    img_boundry = mark_boundaries(temp / 255.0, mask)

    save_file = 'lime_result_bcn.png'
    plt.figure(figsize=(8, 8))
    plt.imshow(img_boundry)
    plt.axis('off')
    plt.savefig(save_file, bbox_inches='tight')
    print(f"‚úÖ ƒê√£ l∆∞u LIME BCN v√†o {save_file}")


if __name__ == '__main__':
    run_lime_bcn()